# TRF5 Web Scraper

Este projeto Ã© um scraper em **Python + Scrapy** para buscar informaÃ§Ãµes de processos no sistema do **TRF5** (Tribunal Regional Federal da 5Âª RegiÃ£o).

O scraper realiza requisiÃ§Ãµes ao endpoint oficial do TRF5 e extrai:

* NÃºmero do processo
* NÃºmero legado
* Data de autuaÃ§Ã£o
* Relator
* Envolvidos (exceto relator)
* MovimentaÃ§Ãµes processuais

---

## ğŸ§© Estrutura do Projeto

```
trf5_scraper/
â”‚
â”œâ”€â”€ scraper/
â”‚   â”œâ”€â”€ spiders/
â”‚   â”‚   â””â”€â”€ trf5_spider.py
â”‚   â”œâ”€â”€ items.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ pipelines.py
â”‚   â”œâ”€â”€ middlewares.py
â”‚   â””â”€â”€ settings.py
â”‚
â”œâ”€â”€ results.jl
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ Como executar o scraper

### 1. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

### 2. Execute o Scrapy passando o nÃºmero do processo:

```bash
scrapy crawl trf5 -a numero_processo=0015648-78.1999.4.05.0000
```

O resultado serÃ¡ salvo no arquivo **results.jl** (JSON Lines).

Se quiser sobrescrever:

```bash
scrapy crawl trf5 -a numero_processo=0015648-78.1999.4.05.0000 -O saida.json
```

---


## ğŸ“ Estrutura do item retornado

O spider retorna um objeto JSON no seguinte formato:

```json
{
  "numero_processo": "1234567-89.2024.4.05.9999",
  "numero_legado": "24.99.123456-7",
  "data_autuacao": "10/02/2024",
  "relator": "DESEMBARGADOR FEDERAL JOÃƒO SILVA",
  "envolvidos": [
    { "papel": "APTE", "nome": "CARLOS ALMEIDA" },
    { "papel": "APDO", "nome": "MARIA FERNANDA" },
    { "papel": "Advogado", "nome": "DR. RICARDO MENDES" }
  ],
  "movimentacoes": [
    { "data": "20/02/2024", "texto": "DistribuiÃ§Ã£o automÃ¡tica realizada." },
    { "data": "25/02/2024", "texto": "Concluso para despacho." },
    { "data": "01/03/2024", "texto": "Despacho proferido pelo relator." }
  ]
}

```

 âš ï¸ IMPORTANTE: Estes dados sÃ£o totalmente fictÃ­cios e servem apenas como exemplo tÃ©cnico.


---
