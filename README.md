# TRF5 Web Scraper

Este projeto Ã© um scraper em **Python + Scrapy** para buscar informaÃ§Ãµes de processos no sistema do **TRF5** (Tribunal Regional Federal da 5Âª RegiÃ£o).

O scraper realiza requisiÃ§Ãµes ao endpoint oficial do TRF5 e extrai:

* NÃºmero do processo
* NÃºmero legado
* Data de autuaÃ§Ã£o
* Relator
* Envolvidos (exceto relator)
* MovimentaÃ§Ãµes processuais

---

## ğŸ§© Estrutura do Projeto

```
trf5_scraper/
â”‚
â”œâ”€â”€ trf5_scraper/
â”‚   â”œâ”€â”€ spiders/
â”‚   â”‚   â””â”€â”€ trf5_spider.py
â”‚   â”œâ”€â”€ items.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ pipelines.py
â”‚   â”œâ”€â”€ middlewares.py
â”‚   â””â”€â”€ settings.py
â”‚
â”œâ”€â”€ results.jl
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ Como executar o scraper

### 1. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

### 2. Execute o Scrapy passando o nÃºmero do processo:

```bash
scrapy crawl trf5 -a numero_processo=0015648-78.1999.4.05.0000
```

O resultado serÃ¡ salvo no arquivo **results.jl** (JSON Lines).

Se quiser sobrescrever:

```bash
scrapy crawl trf5 -a numero_processo=0015648-78.1999.4.05.0000 -O saida.json
```

---

## ğŸ§° UtilizaÃ§Ã£o do arquivo utils.py

FunÃ§Ãµes utilitÃ¡rias usadas em todo o scraper:

* `extract_regex()` â€” extrai dados via regex
* `clean_text()` â€” normaliza e limpa textos
* `xpath_text()` â€” extrai texto de um Ãºnico XPath
* `xpath_texts_join()` â€” extrai mÃºltiplos textos e concatena

Isso melhora a legibilidade (**Clean Code**) e evita duplicaÃ§Ãµes (**DRY**).

---

## ğŸ“ Estrutura do item retornado

O spider retorna um objeto JSON no seguinte formato:

```json
{
  "numero_processo": "0015648-78.1999.4.05.0000",
  "numero_legado": "99.05.15648-8",
  "data_autuacao": "15/04/1999",
  "relator": "DESEMBARGADOR FEDERAL ...",
  "envolvidos": [
    {"papel": "APTE", "nome": "FULANO"},
    {"papel": "APDO", "nome": "BELTRANO"}
  ],
  "movimentacoes": [
    {"data": "01/01/2000", "texto": "MovimentaÃ§Ã£o X"}
  ]
}
```

---

## ğŸ§ª Testes

VocÃª pode criar testes com **pytest** usando mocks para HTML ou responses locais.
Se quiser, posso gerar uma suÃ­te de testes completa.

---

## ğŸ”§ PrincÃ­pios aplicados

* **SOLID**: FunÃ§Ãµes com responsabilidade Ãºnica (Single Responsibility).
* **DRY**: UtilizaÃ§Ã£o do `utils.py` para funÃ§Ãµes repetitivas.
* **KISS**: XPath simples e claros.
* **Clean Code**: Nomes descritivos, docstrings e modularizaÃ§Ã£o.

---

## ğŸ“Œ Melhorias futuras

* Suporte a mÃºltiplos processos em lote
* Retry com backoff exponencial
* ExportaÃ§Ã£o para banco de dados
* CriaÃ§Ã£o de API Flask para consultar processos

---

## ğŸ“„ LicenÃ§a

Este projeto Ã© livre para uso pessoal e estudos.

---

Se quiser, posso adicionar um **badge**, melhorar a documentaÃ§Ã£o ou criar um **Makefile** para facilitar a execuÃ§Ã£o.
